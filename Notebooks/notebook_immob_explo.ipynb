{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.read_csv('valeursfoncieres-2018.txt', sep=\"|\", decimal=\",\")\n",
    "df_2019 = pd.read_csv('valeursfoncieres-2019.txt', sep=\"|\", decimal=\",\")\n",
    "df_2020 = pd.read_csv('valeursfoncieres-2020.txt', sep=\"|\", decimal=\",\")\n",
    "df_2021 = pd.read_csv('valeursfoncieres-2021.txt', sep=\"|\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.shape[0] + df_2019.shape[0] + df_2020.shape[0] + df_2021.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2018,df_2019, df_2020, df_2021], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On paramétrise notre display function pour avoir toutes les variables\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Code departement\"] == 67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Code departement\"] == 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Code departement\"] == 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On extrait les noms des variables\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde le nombre de valeurs unique dans chaque colonne pour enlever les variables qui n'apporte pas d'information\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(len(df[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève donc les variables avec une valeur (souvent NaN) ou d'identifiant (qui n'auront donc pas d'intérêt dans la prédiction ou l'exploration)\n",
    "df.drop(columns=['Identifiant de document', 'Reference document', '1 Articles CGI',\n",
    "       '2 Articles CGI', '3 Articles CGI', '4 Articles CGI', '5 Articles CGI','No disposition', 'No plan', 'Identifiant local', 'No Volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B/T/Q représente l'indice de répétition qui est est une mention qui complète une numérotation de voirie. L’indice de répétition permet de\n",
    "différencier plusieurs adresses portant le même numéro dans la même rue. Elle ne nous servira pas en soit car donc pas car "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"B/T/Q\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde le nombre de valeurs manquantes dans chaque colonne pour enlever les variables qui n'apporte pas d'information\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].isnull().sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de lot est suffisant pour nous indiquer la présence ou non de lots. Le reste est redondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['1er lot',\n",
    "       'Surface Carrez du 1er lot', '2eme lot', 'Surface Carrez du 2eme lot',\n",
    "       '3eme lot', 'Surface Carrez du 3eme lot', '4eme lot',\n",
    "       'Surface Carrez du 4eme lot', '5eme lot', 'Surface Carrez du 5eme lot'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nous occupons désormais de la variable nature culture spéciale qui nous indique la présence ou non d'un extérieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[ \"Nature culture speciale\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Nature culture\"].isna(), \"exterieur\"] = 0\n",
    "df.loc[df[\"exterieur\"].isna(), \"exterieur\"] = 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La présence d'un terrain est clairement indiquer par la surface présente, donc si elle est de 0: il n'y a pas de terrain\n",
    "df.loc[df[\"Surface terrain\"].isnull(), \"Surface terrain\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En s'appuyant sur la documentation, on se rend compte que le relatif aux sections n'est pas pertinent\n",
    "df.drop(columns=[\"Prefixe de section\", \"Section\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On extrait les différentes modalités prises par Nature mutation\n",
    "df[\"Nature mutation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On observe que ce n'est pas pertinent pour notre problématique.\n",
    "df.drop(columns=[\"Nature mutation\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable en relation avec l'adresse se sépare en plusieurs variables, nous allons donc la concaténer. Si l'adresse est nulle, c'est parce qu'il n'y a pas de n° de voie (lieux dits?), donc on remplie adresse avec \"Voie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"key\"]=  df[\"No voie\"].astype(str)+df[\"Voie\"]+df[\"Commune\"]+df[\"Date mutation\"]\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève les références à l'adresse qui ne nous seront d'aucunes utilité\n",
    "df.drop(columns=[\"Type de voie\", \"Voie\", \"No voie\", \"Code voie\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève également le code département qui ne nous servira pas pour récupérer les départements (nous utiliserons le code postal et le nom de la commune)\n",
    "df.drop(columns=[\"Code departement\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ne garder les ventes que de lots uniques, on enlève toutes les ventes qui se répètent plus d'une fois\n",
    "df2 = df.drop_duplicates(subset='key', keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change le format de la date de vente en format datetime.\n",
    "df2.loc[:, 'Date mutation'] = pd.to_datetime(df2['Date mutation'] , format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère le mois et l'année de la vente.\n",
    "df2.loc[:, 'year'] = pd.DatetimeIndex(df2['Date mutation']).year\n",
    "df2.loc[:, 'month'] = pd.DatetimeIndex(df2['Date mutation']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève la clé qui nous a servi à enlever les duplicatas et la date entière qui ne nous sert plus\n",
    "df2.drop(columns=[\"Date mutation\", \"key\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si NaN values dans ces variables de surfaces ou nombre de pièces principales, 0 assigné\n",
    "df2.loc[df2[\"Surface reelle bati\"].isnull(), \"Surface reelle bati\"] = 0\n",
    "df2.loc[df2[\"Surface terrain\"].isnull(), \"Surface terrain\"] = 0\n",
    "df2.loc[df2[\"Nombre pieces principales\"].isnull(), \"Nombre pieces principales\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève la clé qui nous a servi à enlever les duplicatas et la date entière qui ne nous sert plus\n",
    "df2.drop(columns=[\"Nature culture\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève la clé qui nous a servi à enlever les duplicatas et la date entière qui ne nous sert plus\n",
    "df2.drop(columns=[\"Code type local\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2[\"Type local\"].isna(), \"Type local\"] = \"Autres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    print(col)\n",
    "    print(df2[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève les lignes avec des valeurs nulles\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    print(col)\n",
    "    print(df2[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains biens sont à l'euro symbolique ou ont un prix inférieur à 100€, nous enlevons ces biens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On visualise le pourcentage de biens avec un prix de vente inférieur à 100€.\n",
    "euro_symbol = (df2[\"Valeur fonciere\"] < 100).value_counts()\n",
    "\n",
    "plt.pie(euro_symbol, autopct='%.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les biens ayant eu un prix de vente supérieur à 100€.\n",
    "df3 = df2[df2[\"Valeur fonciere\"] > 100]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les différents quartiles pour pouvoir enlever les biens avec un prix anormalement hauts comparés aux autres biens.\n",
    "Q1, Q2, Q3 = df3['Valeur fonciere'].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# On calcule le rang interquartile\n",
    "IQR = Q3-Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On détexte les biens ayant un prix supérieur au troisième quartile multiplié par 1.5 fois le rang interquartile\n",
    "outliers_max = df3[\"Valeur fonciere\"] > (Q3 + 1.5*(IQR))\n",
    "plt.pie(outliers_max.value_counts(), autopct='%.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les biens n'ayant pas un prix de vente anormalement haut.\n",
    "df3 = df3[df3[\"Valeur fonciere\"] < (Q3 + 1.5*(IQR))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liaison avec données des départements et communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la base de données des communes/département\n",
    "departement = pd.read_csv(\"communes-departement-region.csv\")\n",
    "departement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les variables qui nous serviront à cartographier nos données\n",
    "departement  = departement.loc[:,[\"code_postal\", \"nom_commune\", \"nom_departement\",\"nom_region\", \"latitude\", \"longitude\"]]\n",
    "# On met en majuscule le nom des communes pour joindre les bases de données\n",
    "departement[\"nom_commune\"] = departement[\"nom_commune\"].str.upper()\n",
    "departement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une jointure interne entre les deux bases de données\n",
    "df4  = pd.merge(df3, departement, left_on=['Commune', 'Code postal'], right_on=['nom_commune', 'code_postal'], how='inner')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change le type de pièces principales pour la visualisation\n",
    "df4[\"Nombre pieces principales\"] = df4[\"Nombre pieces principales\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On raccourcit le nom de ce type de local pour la visualisation\n",
    "df4.loc[df4[\"Type local\"] == 'Local industriel. commercial ou assimilé', \"Type local\"] = \"Local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3,figsize=(30,12))\n",
    "\n",
    "#create boxplot in each subplot\n",
    "sns.boxplot(data=df4, x=\"month\", y=\"Valeur fonciere\", ax=axes[0,0])\n",
    "sns.boxplot(data=df4, x=\"Type local\", y=\"Valeur fonciere\", ax=axes[0,1])\n",
    "sns.boxplot(data=df4, x=\"Nombre de lots\", y=\"Valeur fonciere\", ax=axes[0,2])\n",
    "sns.boxplot(data=df4, x=\"Nombre pieces principales\", y=\"Valeur fonciere\", ax=axes[1,0])\n",
    "sns.scatterplot(data=df4, x=\"Surface reelle bati\", y=\"Valeur fonciere\", ax=axes[1,1])\n",
    "sns.scatterplot(data=df4, x=\"Surface terrain\", y=\"Valeur fonciere\", ax=axes[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict_fr = {\n",
    "    1: 'Janvier',\n",
    "    2: 'Février',\n",
    "    3: 'Mars',\n",
    "    4: 'Avril',\n",
    "    5: 'Mai',\n",
    "    6: 'Juin',\n",
    "    7: 'Juillet',\n",
    "    8: 'Août',\n",
    "    9: 'Septembre',\n",
    "    10: 'Octobre',\n",
    "    11: 'Novembre',\n",
    "    12: 'Décembre'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"month\"] = [month_dict_fr[month] for month in df4[\"month\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_month = ['Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', 'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df4, x=\"month\", y=\"Valeur fonciere\", category_orders={'month': order_month}, color=\"month\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_departement = df4.pivot_table(index=[\"nom_departement\",\"month\"], values=\"Valeur fonciere\", aggfunc=\"mean\").reset_index()\n",
    "pivot_departement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_order = ['Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', 'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre']\n",
    "\n",
    "# Create a categorical data type with the order of months\n",
    "month_cat = pd.CategoricalDtype(categories=months_order, ordered=True)\n",
    "\n",
    "# Convert the 'month' column to the categorical data type\n",
    "pivot_departement['month'] = pivot_departement['month'].astype(month_cat)\n",
    "\n",
    "# Now sort by the 'month' column\n",
    "pivot_departement = pivot_departement.sort_values(by='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(pivot_departement, x=\"month\", y=\"Valeur fonciere\", color='nom_departement')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_region = df4.pivot_table(index=[\"nom_region\",\"month\"], values=\"Valeur fonciere\", aggfunc=\"mean\").reset_index()\n",
    "\n",
    "# Convert the 'month' column to the categorical data type\n",
    "pivot_region['month'] = pivot_region['month'].astype(month_cat)\n",
    "\n",
    "# Now sort by the 'month' column\n",
    "pivot_region = pivot_region.sort_values(by='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(pivot_region, x=\"month\", y=\"Valeur fonciere\", color='nom_region')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1,figsize=(30,12))\n",
    "sns.boxplot(data=df4, x=\"nom_departement\", y=\"Valeur fonciere\")\n",
    "plt.xticks(rotation=45, ha='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in df4[\"nom_region\"].unique():\n",
    "    print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque region, on construit le boxplot des départements correspondant: \n",
    "for region in df4[\"nom_region\"].unique():\n",
    "    df_graph = df4.loc[df4[\"nom_region\"] == region]\n",
    "    fig = px.box(df_graph, x=\"nom_departement\", y=\"Valeur fonciere\",  color=\"nom_departement\",  title=region)\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1,figsize=(20,12))\n",
    "sns.boxplot(data=df4, x=\"nom_region\", y=\"Valeur fonciere\")\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df4, x=\"nom_region\", y=\"Valeur fonciere\",  color=\"nom_region\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = pd.pivot_table(data=df4, index=[\"longitude\", \"latitude\"], values=\"Valeur fonciere\", aggfunc=\"mean\")\n",
    "mean_values = mean_values.reset_index()\n",
    "mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values['normalized_value'] = (mean_values['Valeur fonciere'] -mean_values['Valeur fonciere'].min()) / (mean_values['Valeur fonciere'].max() - mean_values['Valeur fonciere'].min())\n",
    "mean_values['normalized_value'].plot.hist(bins=30, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(mean_values,\n",
    "                     lat='latitude',\n",
    "                     lon='longitude',\n",
    "                     scope='europe', \n",
    "                    color='Valeur fonciere',\n",
    "                     color_continuous_scale='Inferno',\n",
    "                     # Centré sur la france\n",
    "                     center=dict(lat=46.26, lon=2.52),\n",
    "                     # Normalisé car doit être en 0 et 1\n",
    "                     opacity=mean_values[\"normalized_value\"])\n",
    "\n",
    "#On update la map pour la centrer sur la france\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    height=600,\n",
    "    geo=dict(\n",
    "        center=dict(\n",
    "            lat=46.26,\n",
    "            lon=2.52\n",
    "        ),\n",
    "        scope='europe',\n",
    "        projection_scale=6\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygons de DataGouv: https://www.data.gouv.fr/fr/datasets/contours-des-communes-de-france-simplifie-avec-regions-et-departement-doutre-mer-rapproches/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values_json = pd.pivot_table(data=df4, index=[\"nom_region\"], values=\"Valeur fonciere\", aggfunc=\"mean\")\n",
    "mean_values_json = mean_values_json.reset_index()\n",
    "mean_values_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values_json.loc[mean_values_json[\"nom_region\"] == \"Nouvelle-Aquitaine\", \"nom_region\"] = \"Nouvelle Aquitaine\"\n",
    "mean_values_json.loc[mean_values_json[\"nom_region\"] == \"Grand Est\", \"nom_region\"] = \"Grand-Est\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regions.json\", \"r\") as file:\n",
    "    regions_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the choropleth map\n",
    "fig = px.choropleth(\n",
    "    mean_values_json,  # replace df with your DataFrame\n",
    "    geojson=regions_data,\n",
    "    locations='nom_region',  # replace 'id' with the column name containing the regions' ids\n",
    "    color='Valeur fonciere',  # replace 'value' with the column name containing the values you want to plot\n",
    "    color_continuous_scale='Inferno',\n",
    "    featureidkey=\"properties.libgeo\",  # replace 'properties.id' with the path to the ids in the geojson\n",
    "    range_color=[100000, 250000]\n",
    ")\n",
    "\n",
    "# Update the geos layout to focus on France\n",
    "fig.update_geos(\n",
    "    center={\"lat\": 46.603354, \"lon\": 1.888334},  # Coordinates of France's centroid\n",
    "    projection_scale=15,  # Adjust the scale to fit France\n",
    "    visible=False  # Hide the base map\n",
    ")\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title=\"Choropleth Map of France\",\n",
    "    margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0}\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"departement.json\", \"r\") as file:\n",
    "    dep_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values_json_departement = pd.pivot_table(data=df4, index=[\"nom_departement\"], values=\"Valeur fonciere\", aggfunc=\"mean\")\n",
    "mean_values_json_departement = mean_values_json_departement.reset_index()\n",
    "mean_values_json_departement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the choropleth map\n",
    "fig = px.choropleth(\n",
    "    mean_values_json_departement,  # replace df with your DataFrame\n",
    "    geojson=dep_data,\n",
    "    locations='nom_departement',  # replace 'id' with the column name containing the regions' ids\n",
    "    color='Valeur fonciere',  # replace 'value' with the column name containing the values you want to plot\n",
    "    color_continuous_scale='Inferno',\n",
    "    featureidkey=\"properties.libgeo\"  # replace 'properties.id' with the path to the ids in the geojson\n",
    ")\n",
    "\n",
    "# Update the geos layout to focus on France\n",
    "fig.update_geos(\n",
    "    center={\"lat\": 46.603354, \"lon\": 1.888334},  # Coordinates of France's centroid\n",
    "    projection_scale=15,  # Adjust the scale to fit France\n",
    "    visible=False  # Hide the base map\n",
    ")\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title=\"Choropleth Map of France\",\n",
    "    margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0}\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population active par département: https://www.insee.fr/fr/statistiques/2012710#titre-bloc-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(\"pop_active.xlsx\")\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une jointure interne entre les deux bases de données\n",
    "df5  = pd.merge(df4, pop, on=\"nom_departement\", how='inner')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salaire Net Horaire Moyen par département (2021)- https://www.insee.fr/fr/statistiques/2021266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe le salaire horaire moyen\n",
    "salaire = pd.read_excel(\"base-cc-bases-tous-salaries-2021.xlsx\")\n",
    "salaire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une jointure interne entre les deux bases de données\n",
    "df5  = pd.merge(df5, salaire, on=\"nom_departement\", how='inner')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une matrice de corrélation\n",
    "matrix = df5.loc[:,['Valeur fonciere', 'Nombre de lots', 'Surface reelle bati', 'Nombre pieces principales', 'Surface terrain', \"pop_active\", \"salaire_moyen\"]].corr()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre d'écoles par département\n",
    "https://www.observatoire-des-territoires.gouv.fr/nombre-decoles-elementaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe le dataset avec le nombre d'écoles élémentaires par commune\n",
    "ecole = pd.read_excel(\"ecoles2.xlsx\")\n",
    "ecole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une jointure interne entre les deux bases de données\n",
    "df6  = pd.merge(df5, ecole, on=\"nom_departement\", how='inner')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
